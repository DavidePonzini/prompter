\section{Large Language Models e IA Generativa}
    \todo{Da scrivere}

    \subsection{Large Language Models (LLM) e le loro principali caratteristiche}
        I LLM sono sistemi di IA che utilizzano l'architettura \textit{Transformer} per elaborare e generare linguaggio umano su vasta scala. Questi modelli, grazie ai milioni o miliardi di parametri e all'ampio training su diversi testi, sono capaci di comprendere e produrre testo in modo sorprendentemente umano.
    
        L'architettura transformer è stata introdotta nel 2017 da Google Research nel loro articolo ``Attention is All You Need''. Da allora, questa architettura è diventata la base per la maggior parte dei modelli avanzati di elaborazione del linguaggio naturale (NLP) grazie alla sua efficacia nell'elaborazione di sequenze di dati, come le parole in una frase, e per il suo approccio parallelo nell'elaborazione delle informazioni.
        
        Il Transformer si basa su due componenti principali:
        \begin{itemize}
            \item encoder, che analizza e codifica l'input linguistico in una forma comprensibile per il modello, e
            \item decoder, che utilizza queste informazioni codificate per generare output sequenziali.
        \end{itemize}
            
        Il cuore del Transformer è però il meccanismo di attenzione che permette al modello di valutare l'importanza relativa di ogni parola rispetto alle altre nella stessa frase, migliorando così la qualità della comprensione e della generazione del testo.
        
        Grazie a queste caratteristiche, i Transformer sono ideali per una varietà di applicazioni IA, come la traduzione automatica, la composizione di testi, il riassunto e la risposta a domande. Questi modelli non solo elaborano tutte le parole contemporaneamente, rendendo il processo più veloce, ma sono anche in grado di apprendere sottili sfumature linguistiche, il che li rende strumenti potenti e versatili nel campo dell'IA.

    \subsection{IA Generativa}
        \todo{Da scrivere}

    \subsection{Strumenti e piattaforme per il Prompt Engineering}
        Si è detto che il prompt engineering si concentra sulla progettazione e formulazione di input testuali per guidare i LLM verso la produzione di output desiderato. Tale processo può essere facilitato dall'uso di strumenti e piattaforme opportune. Nel seguito viene riportata una lista, anche se parziale, di tali piattaforme.

        \begin{enumerate}
            \item \textbf{OpenAI GPT-3 e GPT-4}: modelli di linguaggio generativo di OpenAI, noti per generare testo coerente e contestuale da prompt semplici. Gli utenti possono interagire inviando prompt tramite una interfaccia di chat o API e ricevere risposte. Ricercatori e sviluppatori sperimentano con diversi prompt per studiare l'efficacia comunicativa e perfezionare il prompt engineering: \url{https://openai.com/}.

            \item \textbf{Anthropic Claude}: modello di linguaggio generativo costituzionale sviluppato per generare testo fluido e allineato con i valori umani. Utenti, ricercatori e sviluppatori possono interagire in modalità analoga a GPT, inviando richieste testuali e ricevendo risposte dettagliate. Caratteristica distintiva di Claude è il suo addestramento basato sull'approccio Constitutional AI di Anthropic, mirato a sviluppare sistemi di IA che esibiscano comportamenti sicuri, etici e conformi ai valori e agli obiettivi delineati durante l'addestramento: \url{https://www.anthropic.com/}.

            \item Gemini?

            \item \textbf{Hugging Face Transformers}: libreria che offre accesso a centinaia di modelli NLP pre-addestrati come BERT, GPT-2, T5 e altri. Gli sviluppatori possono implementare e testare rapidamente vari modelli con prompt personalizzati, facilitando esperimenti e iterazioni veloci: \url{https://huggingface.co/}.

            \item \textbf{LangChain}: libreria open source che facilita l'applicazione di modelli linguistici a problemi pratici, integrando ragionamento e dialogo. Gli sviluppatori possono costruire applicazioni di prompt engineering per guidare modelli in conversazioni complesse e interazioni utente: \url{https://www.langchain.com/}.

            \item \textbf{Google Cloud Natural Language API}: fornisce accesso a modelli di analisi linguistica per comprendere sentimenti, entità e struttura sintattica del testo. Sebbene non specificamente per il prompt engineering, può essere utilizzata per analizzare e migliorare la qualità di prompt e risposte nel contesto di applicazioni più ampie: \url{https://cloud.google.com/natural-language}.
        \end{enumerate}

        Tali strumenti sono utilizzati in vari settori, dall'arte e design alla produzione di contenuti, passando per la musica e altro ancora. Facciamo, in conclusione di questo paragrafo, alcune riflessioni su alcuni criteri per la scelta di strumenti e piattaforme.

        \begin{itemize}
            \item Costo: Alcuni strumenti possono essere costosi, specialmente per l'uso a livello aziendale.
            \item Accessibilità e usabilità: È importante considerare quanto sia facile imparare a usare lo strumento e integrarlo nei propri flussi di lavoro.
            \item Supporto e comunità: Piattaforme con una vasta comunità e buon supporto sono preferibili, poiché facilitano la risoluzione di problemi e l'apprendimento collaborativo.
        \end{itemize}

        In conclusione, il prompt engineering è un'area di grande interesse e attività, e l'utilizzo di strumenti e piattaforme adeguati può significativamente migliorare la qualità e l'efficacia dei modelli di linguaggio. Questi strumenti aiutano gli sviluppatori a sperimentare e perfezionare i loro approcci, contribuendo al progresso dell'intero campo del NLP.
        
    \subsection{Strumenti di IA Generativa disponibili oggi sul mercato}
        Non è possibile fornire un elenco esatto degli strumenti di IA generativa disponibili sul mercato, in quanto l'ambito della tecnologia IA è in continua evoluzione e espansione. Tuttavia, è possibile delineare alcune delle categorie principali di strumenti di AI Gen con alcuni esempi:

        \begin{itemize}
            \item Generazione di testi:
            \begin{itemize}
                \item \textbf{GPT-3 di OpenAI}: Per generare testi coerenti e contestualmente rilevanti su una vasta gamma di argomenti.
                \item \textbf{BERT di Google}: Per migliorare la comprensione del NL nei motori di ricerca.
                \item \textbf{T5 (Text-To-Text Transfer Transformer)}: Può essere addestrato a svolgere compiti di traduzione, riassunto, classificazione di testo e molto altro.
            \end{itemize}
            \item Generazione di immagini e grafica:
            \begin{itemize}
                \item \textbf{DAVINCI di OpenAI}: Sistema per generare immagini dettagliate da descrizioni testuali.
                \item \textbf{Artbreeder}: Piattaforma che permette di creare immagini attraverso la combinazione di caratteristiche genetiche in un'interfaccia intuitiva.
                \item \textbf{RunwayML}: Fornisce strumenti AI per creativi, permettendo loro di implementare algoritmi di machine learning nei loro flussi di lavoro visivi senza necessità di codifica.
            \end{itemize}
            \item Musica e generazione audio:
            \begin{itemize}
                \item \textbf{Jukebox di OpenAI}: Modello per generare musica, comprese melodie e testi, in vari stili.
                \item \textbf{AIVA (Artificial Intelligence Virtual Artist)}: Compone musica sinfonica e per videogiochi.
            \end{itemize}
            \item Video e Animazione:
            \begin{itemize}
                \item \textbf{Synthesia}: Crea video in cui un avatar personalizzato parla con la voce sintetizzata, ideale per video educativi o di marketing.
                \item \textbf{DeepBrain AI}: Crea video in cui figure umane virtuali interagiscono in tempo reale.
            \end{itemize}
            \item Contenuto per il Web e pubblicità:
            \begin{itemize}
                \item \textbf{Persado}: Utilizza IA per generare testi persuasivi ottimizzati per pubblicità e marketing.
                \item \textbf{Copysmith}: Piattaforma che sfrutta GPT-3 per generare contenuti pubblicitari, blog e altro materiale scritto.
            \end{itemize}
            \item Giochi e Intrattenimento:
            \begin{itemize}
                \item \textbf{AI Dungeon}: Un gioco di avventura testuale alimentato da AI che genera contenuti dinamici in risposta alle scelte dei giocatori.
            \end{itemize}
        \end{itemize}

        Questi sono solo alcuni esempi delle tecnologie AI Gen disponibili sul mercato. Ogni categoria ha una pletora di prodotti sviluppati da start-up e grandi aziende, ognuno con i propri unici punti di forza e aree di applicazione. Con l'evoluzione continua delle capacità di IA e machine learning, il numero e la sofisticatezza di questi strumenti sono destinati a crescere ulteriormente.
    
        \subsubsection{Applicazioni pratiche}
            L'importanza del prompt engineering si manifesta nella sua capacità di influenzare l'output di modelli di IA, rendendolo pertinente e utile per molteplici contesti operativi. Per esempio, nel settore educativo, in cui prompt ben strutturati possono aiutare i modelli di IA a fornire spiegazioni dettagliate o semplificate a seconda del livello di comprensione degli studenti, oppure nel commercio, in cui prompt ben strutturati possono personalizzare le interazioni con i clienti per migliorare l'esperienza utente e incrementare la soddisfazione del cliente.

            Riportiamo nel seguito alcuni esempi pratici di prompt specifici per ottenere risposte utili e personalizzate in vari contesti, utilizzando ChatGPT e Claude.

            \begin{itemize}
                \item \textbf{Spiegazione semplificata di concetti scientifici}
                \begin{itemize}
                    \item Prompt: \textit{``Spiega il concetto di fotosintesi a un bambino di 10 anni.''}
                    \item Utilizzo: Rende comprensibili concetti scientifici complessi a giovani studenti o a chi non ha una formazione specifica in biologia.
                \end{itemize}
                
                \item \textbf{Comprensione di concetti complessi}
                \begin{itemize}
                    \item Prompt: \textit{``Puoi spiegarmi il principio di incertezza di Heisenberg in termini semplici?''}
                    \item Utilizzo: Aiuta gli studenti a comprendere concetti fisici avanzati in modo più accessibile.
                \end{itemize}
                
                \item \textbf{Aiuto nei compiti}
                \begin{itemize}
                    \item Prompt: \textit{``Come posso risolvere questa equazione differenziale: }\textless{}segue descrizione dell'equazione\textgreater{}\textit{?''}
                    \item Utilizzo: Fornisce passaggi dettagliati per aiutare gli studenti con specifici problemi matematici.
                \end{itemize}
                
                \item \textbf{Preparazione agli esami}
                \begin{itemize}
                    \item Prompt: \textit{``Crea un quiz su `Il Gattopardo' di Tomasi di Lampedusa per prepararmi all'esame di letteratura italiana.''}
                    \item Utilizzo: Genera domande di pratica che possono aiutare gli studenti a testare la loro comprensione dei materiali di studio.
                \end{itemize}
                
                \item \textbf{Supporto clienti}
                \begin{itemize}
                    \item Prompt: \textit{``Il mio volo è stato cancellato, cosa posso fare?''}
                    \item Utilizzo: Fornisce informazioni immediate e soluzioni ai clienti che affrontano problemi di viaggio.
                \end{itemize}
                
                \item \textbf{Raccomandazioni di prodotti}
                \begin{itemize}
                    \item Prompt: \textit{``Suggeriscimi alcuni libri di fantascienza basati sui bestseller recenti.''}
                    \item Utilizzo: Aiuta i clienti a scoprire nuovi prodotti basati sui loro interessi e sulle tendenze attuali.
                \end{itemize}
                
                \item \textbf{Organizzazione personale}
                \begin{itemize}
                    \item Prompt: \textit{``Aiutami a pianificare il mio itinerario di viaggio per una settimana a Tokyo.''}
                    \item Utilizzo: Fornire suggerimenti per attrazioni, cibo, e trasporti, personalizzando l'esperienza di viaggio.
                \end{itemize}
                
                \item \textbf{Risoluzione di problemi}
                \begin{itemize}
                    \item Prompt: \textit{``Come posso migliorare la ricezione del Wi-Fi in casa?''}
                    \item Utilizzo: Offre consigli tecnici per migliorare la connettività Internet domestica.
                \end{itemize}
                
                \item \textbf{Creatività e scrittura}
                \begin{itemize}
                    \item Prompt: \textit{``Scrivi il paragrafo introduttivo di un racconto che inizia con un risveglio in una città sconosciuta.''}
                    \item Utilizzo: Stimola la creatività e fornisce un punto di partenza per scrittori e appassionati di narrativa.
                \end{itemize}
                
                \item \textbf{Supporto nella progettazione di sistemi}: un assistente virtuale che può guidarti nella progettazione, implementazione e verifica di sistemi. Per esempio, vogliamo progettare un antifurto basato su Arduino. In questo caso, il processo è più articolato e occorre prevedere diversi prompt per diverse fasi del progetto. Vediamo come procedere.
                \begin{itemize}
                    \item \textbf{Definizione del progetto}: Definire chiaramente l'obiettivo del progetto.
                    \begin{itemize}
                        \item Prompt: \textit{``Quali sono i componenti essenziali per un sistema antifurto basato su Arduino?''}
                        \item Prompt: \textit{``Quali sensori sono più adatti per rilevare intrusioni in un ambiente domestico?''}
                        \item Utilizzo: ricevere una lista di componenti hardware necessari: sensori di movimento (PIR), sensori di contatto per porte e finestre, moduli di comunicazione (come WiFi o GSM).
                    \end{itemize}
                    
                    \item \textbf{Ricerca e selezione componenti}: Dopo aver definito i componenti, si possono chiedere informazioni.
                    \begin{itemize}
                        \item Prompt: \textit{``Come funziona un sensore PIR con Arduino?''}
                        \item Prompt: \textit{``Quali librerie Arduino posso usare per gestire un modulo GSM?''}
                        \item Utilizzo: ricevere esempi di codice, spiegazioni sul funzionamento dei sensori e suggerimenti su librerie e risorse utili per il progetto.
                    \end{itemize}
                    
                    \item \textbf{Schema di collegamento}: Chiedere indicazioni per creare uno schema di collegamento dei componenti.
                    \begin{itemize}
                        \item Prompt: \textit{``Come collego un sensore PIR a un Arduino Uno?''}
                        \item Prompt: \textit{``Qual è lo schema di collegamento per un modulo GSM con Arduino?''}
                        \item Utilizzo: sul collegamento dei vari componenti elettronici; ricevere anche suggerimenti su pratiche ottimali per la sicurezza e la stabilità del sistema.
                    \end{itemize}
                    
                    \item \textbf{Scrittura del Codice}: Chiedere aiuto per la scrittura del codice necessario per il funzionamento del sistema.
                    \begin{itemize}
                        \item Prompt: \textit{``Puoi aiutarmi a scrivere un codice Arduino per un sistema antifurto che attivi un allarme quando un sensore PIR rileva movimento?''}
                        \item Prompt: \textit{``Come posso programmare Arduino per inviare un SMS di allarme tramite modulo GSM quando si attiva il sensore di porta?''}
                        \item Utilizzo: ricevere snippet di codice o guide passo passo per programmare le funzionalità desiderate dell'antifurto.
                    \end{itemize}
                    
                    \item Testing e Debugging
                    \begin{itemize}
                        \item Prompt: \textit{``Quali sono le tecniche comuni per il debugging di un progetto Arduino?''}
                        \item Prompt: \textit{``Come posso testare l'efficacia del mio sistema antifurto prima di installarlo?''}
                        \item Utilizzo: ricevere suggerimenti per il testing e il debugging del sistema.
                    \end{itemize}
                \end{itemize}
            \end{itemize}

            In sintesi, il prompt engineering non solo migliora la funzionalità e l'accessibilità dei sistemi di IA, ma apre anche nuove strade per la loro applicazione pratica in campi sempre più ampi, evidenziando l'intersezione tra la tecnologia avanzata e le esigenze umane quotidiane.
            
    \subsection{Concetti base dell'architettura Transformer}
        Prima che emergessero in modo ``dirompente'' i modelli basati sull'architettura Transformer, vi erano vari tipi di Large Language Models (LLM) che utilizzavano altre architetture di rete neurale. Alcuni dei più noti sono basati su architetture di Reti Neurali Ricorrenti (Recurrent Neural Network - RNN) e le loro varianti come LSTM (Long Short-Term Memory) e GRU (Gated Recurrent Units). Questi modelli erano ampiamente utilizzati per il trattamento di sequenze di dati, in particolare nel linguaggio naturale (Natural Language – NL).

        Anche se i modelli basati su Transformer sono oggi dominanti nel campo dell'elaborazione del linguaggio naturale (Natural Language Processing – NLP) grazie alla loro maggiore efficienza e capacità di gestire lunghe dipendenze, questi modelli più vecchi hanno ancora applicazioni valide e continuano ad essere oggetto di ricerca e sviluppo per specifici scenari d'uso, come generazione di testo, completamento automatico del testo, riconoscimento del parlato, analisi dei sentimenti, traduzione automatica. Questi modelli dimostrano che, nonostante l'efficienza dei Transformer in molte aree, le RNN e le loro varianti rimangono tecniche preziose e rilevanti per molti compiti di elaborazione delle sequenze. Ogni tipo di modello ha suoi punti di forza e sue limitazioni, e la scelta del modello più adatto può dipendere da diversi fattori, tra cui natura del compito, disponibilità di dati di addestramento, risorse computazionali disponibili.
        
        Il concetto di ``prompt engineering'' è più comunemente associato con i modelli di linguaggio più recenti basati su Transformer, come GPT o Claude, che sono in modo particolare sensibili e reattivi agli input specifici (prompt) che ricevono. Questo è dovuto alla loro capacità di generare risposte coerenti e dettagliate basate su enormi quantità di dati di addestramento. Tuttavia, la tecnica di fornire input specificamente formulati per ottenere i risultati desiderati può essere applicata, in una certa misura, anche ai modelli basati su RNN, LSTM e GRU. In generale, il prompt engineering in contesti che non includono modelli Transformer è meno accentuato e spesso non è etichettato esplicitamente come tale. Tuttavia, il principio di ottimizzare e adattare gli input per migliorare le prestazioni del modello è un concetto fondamentale nel machine learning e può essere applicato a qualsiasi tipo di modello, compresi RNN, LSTM e GRU.
        
    \subsection{LLM basati su architettura Transformer}
        Alcuni dei principali modelli basati su architettura Transformer sono:
        \begin{itemize}
            \item \textbf{BERT (Bidirectional Encoder Representations from Transformers)} è utilizzato principalmente per compiti di comprensione del testo, come analisi del sentimento, classificazione dei testi e domande/risposte. Alcune varianti:
            \begin{itemize}
                \item \textbf{RoBERTa (Robustly Optimized BERT Approach)}: variante ottimizzata tramite un training su un data set più grande e per più tempo rispetto a BERT, migliorando la comprensione del testo;
                
               \item \textbf{ DistilBERT}: versione semplificata e ottimizzata progettata per essere più veloce e leggera, pur mantenendo una buona parte delle capacità del modello originale. È particolarmente utile per applicazioni che richiedono modelli più leggeri e veloci;
                
                \item \textbf{XLNet}: modello che supera alcune limitazioni di BERT utilizzando una permutazione dell'ordine delle parole nel testo durante il training, permettendo al modello di apprendere meglio il contesto e migliorando le prestazioni su compiti come completamento di frasi e domande/risposte.
            \end{itemize}
            
            \item \textbf{GPT (Generative Pre-trained Transformer)} e le sue versioni successive, come GPT-2, GPT-3, e GPT-4, sono modelli generativi che possono produrre testi coerenti e contestualmente appropriati basandosi su un prompt iniziale;
            
            \item \textbf{T5 (Text-to-Text Transfer Transformer)}: modello che interpreta tutte le attività di NLP come un problema di trasformazione del testo da un formato all'altro, rendendolo estremamente versatile per vari compiti come la traduzione automatica, il riassunto di testi e le domande e risposte.
            
            \item \textbf{Claude}: modello di linguaggio sviluppato da Anthropic, startup di IA co-fondata da ex ricercatori di OpenAI. Questo modello segue le orme di altri modelli di linguaggio di grandi dimensioni, come GPT di OpenAI e BERT di Google. Claude è progettato per essere un modello di conversazione più sicuro e meno propenso a generare risposte dannose o inesatte, grazie a miglioramenti nell'addestramento e nella sintonizzazione del modello, mantenendo l'efficienza dell'architettura transformer per gestire compiti di NLP complessi.
        \end{itemize}
        
        \subsubsection{LLM, architettura Transformer e machine learning}
            LLM e architettura Transformer sono strettamente correlati al machine learning (ML), con riferimento particolare all'apprendimento profondo (deep learning), sotto-categoria di algoritmi ML caratterizzata dall'uso di reti neurali con molteplici livelli di elaborazione.
            \begin{itemize}
                \item \textbf{Reti Neurali Profonde}: I LLM, come GPT, BERT, Claude, … sono basati su reti neurali profonde, che sono uno degli strumenti principali nel ML per modellare complessi pattern nei dati. Queste reti apprendono da vasti dataset per generalizzare nuove informazioni che non sono state viste durante l'addestramento.
                
                \item \textbf{Architetture avanzate}: L'architettura Transformer, che è al cuore di molti LLM, rappresenta un'innovazione significativa nel ML per il NL. I Transformer utilizzano un meccanismo di attenzione (citato in precedenza) che permette al modello di considerare l'intera sequenza di input contemporaneamente, migliorando la capacità di gestire dati sequenziali rispetto ai precedenti modelli di rete neurale.
                
                \item \textbf{Training e inferenza}: Nel ML, il processo di addestramento consiste nell'ottimizzare i parametri della rete neurale (pesi e bias) attraverso la minimizzazione di una funzione di perdita, che misura quanto bene il modello predice il dato di output rispetto all'output atteso. I LLM sono tipicamente addestrati su compiti di predizione del testo seguente dato un testo precedente, per poi essere utilizzati in una varietà di applicazioni di inferenza, come completamento automatico di testo, risposta a domande, e traduzione.
                
                \item \textbf{Scalabilità e prestazioni}: I Transformer hanno dimostrato di scalare efficacemente con l'aumentare delle dimensioni del modello e della quantità di dati di addestramento, portando a miglioramenti sostanziali nelle prestazioni. Questo ha reso i LLM basati su Transformer particolarmente potenti, poiché possono trattare e generare linguaggio con una naturalezza e una fluidità che modelli precedenti non erano capaci di raggiungere.
            \end{itemize}
            
            In conclusione, i LLM e i modelli basati su Transformer sono esempi di come il ML possa essere applicato per risolvere problemi complessi di NLP, sfruttando l'apprendimento profondo per interpretare, generare e interagire con il linguaggio umano in modo sempre più sofisticato.
        
        \subsubsection{Caratteristiche rilevanti dei LLM}
            Questi modelli hanno rivoluzionato il modo in cui interagiamo con le macchine, permettendo sviluppi significativi in applicazioni come gli assistenti virtuali, gli strumenti di traduzione automatica, le piattaforme di assistenza clienti automatizzate e molti altri sistemi basati sul linguaggio. Ecco alcune caratteristiche rilevanti su queste categorie di modelli:
            \begin{enumerate}
                \item
                    \textbf{Dimensione e complessità}: Gli LLM sono noti per il loro numero elevato di parametri e dati di addestramento, che può variare da centinaia di milioni a diversi miliardi.
            
                    I parametri sono fondamentalmente le ``regole di apprendimento'' che il modello utilizza per fare previsioni e generazioni dopo essere stato addestrato.
                    
                    Un ``parametro'' in un modello di machine learning può essere pensato come una variabile all'interno del modello che viene adattata durante il processo di addestramento.
                    
                    Ad esempio, modelli come GPT-3 hanno fino a 175 miliardi di parametri.
                    
                    Maggiore è il numero di parametri, maggiore è la capacità del modello di apprendere da una vasta gamma di dati e catturare relazioni più complesse all'interno di quel dataset; Con troppi parametri, c'è il rischio che il modello si adatti troppo bene ai dati di addestramento, perdendo la capacità di generalizzare bene su nuovi dati (overfitting); I modelli con molti parametri richiedono più potenza di calcolo per l'addestramento e l'inferenza, il che può aumentare significativamente i costi e l'impatto ambientale.
                    
                    La ``dimensione e complessità'' si concentra quindi sulle caratteristiche interne del modello e sul suo potenziale teorico di apprendimento basato sulla quantità di parametri.
                    
                    Questo ampio numero di parametri permette ai LLM di catturare e modellare sottili sfumature linguistiche e complessità. Addestramento su dataset di grandi dimensioni
                
                \item
                    \textbf{Addestramento su dataset di grandi dimensioni}: Gli LLM sono addestrati su vasti corpus di testo che spesso comprendono una vasta gamma di informazioni raccolte da internet o da altre fonti selezionate.
            
                    Addestrare su vasti dataset permette al modello di essere esposto a un'ampia varietà di informazioni, lingue, argomenti e stili di scrittura, aumentando la sua utilità in applicazioni diverse; L'esposizione a diversi tipi di dati durante l'addestramento può aiutare il modello a generalizzare meglio, cioè a performare bene su tipi di dati che non ha visto durante l'addestramento; Sebbene un vasto dataset possa migliorare la generalizzazione, può anche introdurre o perpetuare bias esistenti nei dati, influenzando le performance e l'equità del modello.
                    
                    L'``addestramento su dataset di grandi dimensioni'' riguarda il modo in cui il modello viene esposto a varie informazioni e come queste informazioni formano la base della sua ``comprensione'' e delle sue capacità di previsione.
                    
                    Questo addestramento estensivo permette ai modelli di avere una conoscenza più ampia del linguaggio umano e delle sue varie applicazioni.

                \item
                    \textbf{Versatilità}: Grazie alla loro ampia conoscenza generale e capacità di modellare il linguaggio, gli LLM sono estremamente versatili e possono essere utilizzati per una varietà di compiti di elaborazione del linguaggio, da semplici compiti come la classificazione del testo a compiti più complessi come generazione di testo coerente e contestualmente appropriato.

                \item
                    \textbf{Adattabilità}: Nonostante la loro ampia formazione, gli LLM possono essere ulteriormente adattati o specializzati su compiti o domini specifici attraverso tecniche come il ``fine-tuning''. Questo li rende utili in settori specifici come la legge, la medicina o il servizio clienti, dove è necessaria una comprensione specializzata.

                \item
                    \textbf{Problemi e sfide}: Nonostante i loro vantaggi, gli LLM presentano anche sfide (che discuteremo più avanti), come gestione del bias nei dati, produzione di risposte errate o fuorvianti e la loro grande necessità di risorse per l'addestramento e l'esecuzione, che li rende meno sostenibili dal punto di vista ambientale ed economico rispetto a modelli più piccoli.
            \end{enumerate}
             
        \subsubsection{Come funzionano i LLM}
            I LLM sono una componente fondamentale dell'evoluzione recente nel campo dell'IA, guidando molti degli sviluppi più innovativi nell'elaborazione del NL e nelle interazioni uomo-macchina. Per capire come funzionano in termini semplici, possiamo suddividerne il funzionamento nelle seguenti tre fasi principali:
            \begin{enumerate}
                \item
                    \textbf{Addestramento}: Gli LLM sono addestrati su grandi quantità di testo; Questo può includere libri, articoli, siti web, e altro ancora. Durante l'addestramento, il modello analizza i testi per capire come le parole si combinano per formare frasi, come le frasi costruiscono paragrafi, e come i paragrafi possono esprimere idee complesse. Il modello impara le regole grammaticali, i significati delle parole, e le relazioni tra di esse. Questo processo richiede enormi quantità di dati e capacità di calcolo. Alcune note meritano di essere aggiunte relativamente ad particolare tipo di addestramento denominato da Anthropic con il temine di ``costituzionale''.
            
                    L'addestramento costituzionale (o constitutional training) è un approccio utilizzato nell'addestramento di alcuni modelli di IA, per cercare di migliorarne l'affidabilità, la sicurezza e l'allineamento con determinati valori e principi etici. In sostanza, durante la fase di addestramento vengono aggiunti al dataset esempi ed istruzioni esplicite che codificano determinate regole di comportamento, valori deontologici, conoscenze fattuali affidabili e restrizioni su ciò che il modello dovrebbe o non dovrebbe fare nelle sue risposte e output. Lo scopo è quello di ``costituzionalizzare'' il modello, ovvero renderlo più stabile, coerente e ancorato a principi di base concordati, riducendo il rischio di derive indesiderate o pericolose quando viene utilizzato. È un tentativo di instillare una sorta di ``costituzione'' comportamentale nel modello fin dalla sua formazione. Questo approccio non elimina del tutto il rischio di allucinazioni o di altre problematiche nei modelli di IA (che discuteremo nel dettaglio nel seguito del documento), ma mira a limitarne la portata indirizzando il modello verso risposte più sicure, etiche e costituzionalmente allineate con valori stabiliti.

                \item
                    \textbf{Apprendimento}: Mentre analizza il testo, il modello costruisce una sorta di ``memoria interna'' o una rappresentazione del linguaggio. Utilizza strutture matematiche chiamate vettori per rappresentare concetti e parole. Più il modello incontra una parola o una struttura in vari contesti, meglio riesce a comprendere il suo uso e significato. Il concetto di vettori di parole (``word embedding'') è una parte fondamentale del meccanismo di apprendimento e rappresentazione del linguaggio. Questi vettori sono rappresentazioni matematiche di alta dimensione che cercano di catturare il significato delle parole, i loro usi e le loro relazioni con altre parole. Ogni vettore è essenzialmente un array di numeri che il modello di linguaggio impara durante il suo addestramento. Per fornire un esempio concreto, ecco come potrebbe essere rappresentato il vettore per la frase ``Cappuccetto Rosso'' dopo che il modello ha letto la fiaba.

                    È importante notare che il vettore effettivo sarebbe molto più complesso e ad alta dimensione (tipicamente dimensioni dell'ordine delle centinaia), ma qui forniamo una versione semplificata per illustrare il concetto:

                    \texttt{["Cappuccetto Rosso"] = [0.85, -0.32, 0.91, ..., 0.45]}

                    In questa rappresentazione semplificata, ogni numero nel vettore rappresenta un aspetto del significato associato alla frase ``Cappuccetto Rosso'' nel contesto della fiaba. Questi potrebbero includere:
                    \begin{itemize}
                        \item \texttt{0.85}: forte correlazione con temi di innocenza o vulnerabilità.
                        \item \texttt{-0.32}: una leggera correlazione negativa con concetti di sicurezza o protezione.
                        \item \texttt{0.91}: alta correlazione con il tema della pericolosità o dell'inganno (riferendosi al lupo).
                        \item ...
                        \item \texttt{0.45}: una moderata correlazione con l'avventura o il viaggio.
                    \end{itemize}
                    Questa fase permette al modello di catturare e memorizzare la complessità del linguaggio umano.

                \item
                    \textbf{Generazione}: Quando viene utilizzato, il modello riceve un ``prompt'' dall'utente, che può essere una frase, una domanda o anche solo una parola. Basandosi su ciò che ha appreso durante l'addestramento, il modello cerca di prevedere e generare la risposta o il testo più probabile che segue l'input. Il modello fa questo cercando tra le rappresentazioni interne che ha costruito e selezionando le parole che ritiene più appropriate per completare il testo.
            
                    Questo processo si basa sulla probabilità: il modello calcola quale parola (o parole) ha la maggiore probabilità di seguire logicamente l'input basato sui testi che ha studiato durante l'addestramento.
                    
                    Il modello utilizza questi numeri per determinare come ``Cappuccetto Rosso'' si relaziona a altre parole o frasi nel testo. Per esempio, se il modello deve completare una frase iniziata con ``Cappuccetto Rosso'', utilizzerà il vettore per prevedere le parole che probabilmente seguiranno basandosi sulle relazioni apprese. In pratica, questi vettori sono generati e utilizzati dai modelli di linguaggio senza che l'utente finale debba interagire direttamente con essi. La manipolazione e l'interpretazione di questi vettori avviene internamente nel modello, che usa algoritmi complessi per ottimizzare e adattare questi vettori durante l'addestramento per migliorare la loro capacità di rappresentare accuratamente il linguaggio umano.
            \end{enumerate}
            
            In sintesi, i LLM funzionano analizzando grandi quantità di testo per costruire una comprensione interna del linguaggio, che poi utilizzano per produrre testo che è coerente e pertinente agli input ricevuti. Questi modelli sono potentemente versatili, permettendo di generare testo in molti stili e formati diversi, e di rispondere a una vasta gamma di richieste e domande.
            
            La progettazione di prompt efficaci per questi modelli è essenziale per sfruttare al meglio le loro capacità e ottenere risultati desiderati in vari contesti di utilizzo.
            
    \subsection{Come avviene il processo di interpretazione dei prompt}
        \todo{Da scrivere}
        
    \subsection{Il concetto di ``embedding''}
        \todo{Da scrivere}
        
    \subsection{``Punti di attenzione'' e ``fine-tuning''}
        \todo{Da scrivere}
    
    \subsection{I principali parametri di configurazione di un LLM}
        Quando si utilizza un LLM come GPT o Claude, si può interagire direttamente con il modello attraverso un'API, che consente di configurare diversi parametri per ottimizzare le risposte del modello in base alle necessità specifiche. Questi parametri includono:
        \begin{itemize}
            \item Top P,
            \item Lunghezza massima,
            \item Sequenze di stop,
            \item Penalità di frequenza
            \item Penalità di presenza.
        \end{itemize}
        
        Ciascuno di questi parametri ha uno scopo specifico nella modulazione delle risposte del modello, permettendo di bilanciare tra creatività, specificità e concisione delle risposte generate.
        
        Di seguito viene fornita una spiegazione di questi parametri e un esempio pratico del loro uso con GPT e con Claude.
        
        \subsubsection{Temperatura}
            La temperatura è un parametro che influisce sul livello di casualità o determinismo nelle risposte generate dal modello. Questo parametro è essenziale per modulare come il modello sceglie il prossimo token (parola o parte di essa) durante il processo di generazione del testo. Può assumere valori tipicamente compresi tra 0 e 1, anche se sono possibili valori più alti.
            \begin{itemize}
                \item Temperatura bassa (<0.5): rende il modello più deterministico. Con una temperatura vicina a zero, il modello tende a scegliere ripetutamente i token più probabili, risultando in risposte molto prevedibili e meno varie: valore adeguato per compiti che richiedono precisione e affidabilità;
                
                \item Temperatura alta (>0.5): aumenta la casualità nelle scelte dei token. Ciò significa che il modello ha maggiori probabilità di selezionare token meno probabili, portando a risposte più creative, variabili e a volte inaspettate: valore adeguato per compiti che richiedono creatività, come scrivere poesie, storie, o generare idee innovative.
            \end{itemize}

            \textbf{Uso}: parametro utile per adattare il modello a compiti che richiedono più o meno originalità e varietà.
            
        \subsubsection{Top p (nucleus sampling)}
            Il parametro Top P, conosciuto anche come \textit{nucleus sampling}, è importante per controllare il comportamento del generatore di testo; è un metodo di campionamento che seleziona il prossimo token da un sottoinsieme ridotto del vocabolario del modello.

            Il valore di \texttt{top\_p} rappresenta la probabilità cumulativa e determina la grandezza di questo sottoinsieme. In pratica, si configura il modello per considerare il più piccolo insieme di token il cui valore cumulativo delle probabilità supera il valore di \texttt{top\_p}. Per es., con \texttt{top\_p = 0.9}, si stanno includendo solo i token più probabili che, insieme, accumulano il 90\% della probabilità totale. In altre parole, per ogni scelta del prossimo token, il modello guarda al set di token che costituiscono il 90\% più probabile e seleziona da lì, escludendo token meno probabili che cumulativamente costituiscono il restante 10\%. Questo è fatto per assicurare che il testo generato sia ragionevolmente probabile (non troppo bizzarro o imprevedibile), ma allo stesso tempo permette una certa varietà e creatività nella generazione della risposta.

            \textbf{Uso}: parametro utile per bilanciare la generazione tra risposte convenzionali e innovative, a seconda del contesto.
        
        \subsubsection{Lunghezza massima}
            Il parametro lunghezza massima determina il numero massimo di token che il modello può generare come risposta.	Impostare questo parametro permette di prevenire risposte eccessivamente lunghe o divagazioni.

            \textbf{Uso}: parametro importante per mantenere le risposte concise e pertinenti, specialmente in applicazioni interattive o quando si desiderano risposte brevi.
            
        \subsubsection{Sequenze di stop}
            Parametro che specifica i token o una sequenza di token che, se generati, causeranno l'interruzione della generazione del testo. Questo aiuta a controllare la struttura e la lunghezza della risposta.

            \textbf{Uso}: parametro utilizzato per definire un punto di terminazione chiaro nelle risposte, come la fine di un elenco o di un paragrafo.
            
        \subsubsection{Penalità di frequenza}
            Il parametro penalità di frequenza, unitamente al parametro successivo penalità di presenza, aiuta a controllare la ripetizione (dei token) delle parole nel testo generato. Il parametro penalità di frequenza modifica la probabilità di selezione di un token in base alla frequenza con cui è già apparso nel testo corrente. Il valore di questa penalità può variare da 0 a 2 e influisce su come il modello ``penalizza'' i token già usati:
            \begin{itemize}
                \item 0: non viene applicata alcuna penalità. Il modello può ripetere parole o frasi senza alcun condizionamento.
            
                \item Positivo: ogni volta che un token viene generato, la sua probabilità di essere scelto di nuovo viene ridotta. Per esempio, un valore di \texttt{frequency\_penalty = 0.5} significa che la probabilità di selezionare nuovamente un token già apparso viene diminuita in modo significativo, ma non del tutto, ogni volta che il token è usato. Questo aiuta a ridurre le ripetizioni senza eliminare completamente la possibilità che parole chiave rilevanti ricompaiano nel testo.
            
                \item Alto (vicino a 2): rende molto improbabile la ripetizione di parole, promuovendo una diversità estrema nel testo generato che potrebbe, a volte, compromettere la sua coerenza e leggibilità.
            \end{itemize}
            
            La penalità di frequenza è particolarmente utile in applicazioni di generazione di testo dove la qualità e la leggibilità del contenuto sono cruciali, come nella scrittura creativa, nella redazione di articoli, nella creazione di contenuti per il marketing e nella generazione automatica di report. In questi contesti, evitare ripetizioni inutili e promuovere la ricchezza del linguaggio sono aspetti fondamentali per rendere il testo più accattivante e professionale.
            
        \subsubsection{Penalità di presenza}
            Il parametro penalità di presenza è progettato per influenzare la varietà delle risposte generate dal modello modificando la probabilità di selezione dei token che sono già apparsi nel testo. Questo parametro è particolarmente utile per incoraggiare la generazione di contenuto nuovo e diversificato, riducendo la tendenza del modello a ripetere gli stessi concetti o frasi; aggiunge una penalità ai token ogni volta che compaiono nel testo generato, a prescindere dalla frequenza con cui sono apparsi.

            A differenza della penalità di frequenza, che penalizza i token in base alla frequenza delle loro apparizioni, la penalità di presenza si applica uniformemente ogni volta che un token ricompare.
            \begin{itemize}
                \item 0: non viene applicata alcuna penalità per la presenza di token, consentendo al modello di ripetere liberamente parole o frasi senza alcun deterrente.
            
                \item Basso: impostare per esempio un valore di \texttt{presence\_penalty = 0.2} significa che la probabilità di selezionare di nuovo un token già utilizzato viene leggermente ridotta. Questo impedisce al modello di ripetere troppo spesso lo stesso concetto o frase, promuovendo l'introduzione di idee nuove nel testo.
            
                \item Alto (vicino a 1 o superiore): una penalità di presenza alta scoraggia fortemente la ripetizione di qualsiasi token già usato, spingendo il modello a esplorare nuovi territori linguistici e concettuali, il che può essere utile per stimolare la creatività ma a rischio di perdere coerenza.
            \end{itemize}
            
            La penalità di presenza è utile in scenari dove è richiesta la generazione di contenuti freschi e originali ma dove è anche importante mantenere una narrazione o una discussione coesa e logica. Esempi includono il brainstorming di idee, la scrittura creativa, la generazione di contenuti didattici innovativi, o la conversazione interattiva in cui è desiderabile evitare la stagnazione tematica.
            
    \subsection{Esempio pratico di uso con GPT}
        Supponiamo che un'azienda di voler utilizzare GPT-3 per avere una spiegazione relativa al seguente problema:

        \begin{center}
            \textit{``Spiega i benefici dell'energia solare per le abitazioni residenziali.''}
        \end{center}

        \begin{itemize}
            \item
                \textbf{Temperatura}: Impostata a 0.7 implica che il modello è configurato per generare testo che è relativamente creativo e vario, ma ancora guidato in gran parte dalle probabilità linguistiche apprese durante l'addestramento. Con questo valore, il modello non è così casuale da perdere coerenza, ma è abbastanza aperto da introdurre elementi interessanti e meno prevedibili nel testo. Ecco alcune considerazioni.
                \begin{itemize}
                    \item Creatività moderata: con una temperatura di 0.7, il modello può esplorare opzioni di risposta leggermente più ampie senza diventare troppo divergente o irrilevante, il che è utile per compiti che richiedono un certo livello di inventiva, come la scrittura creativa o la pubblicità.

                    \item Coerenza mantenuta: nonostante la maggiore apertura alla casualità, una temperatura di 0.7 mantiene una forte aderenza al linguaggio e ai pattern appresi durante l'addestramento, assicurando che le risposte restino logiche e comprensibili.
                
                    \item Adattabilità: Questo livello di temperatura consente al modello di adattarsi a vari contesti, rendendolo adatto per applicazioni che richiedono una risposta equilibrata tra nozione e novità, come nelle risposte di assistenti virtuali, generazione di contenuti educativi e supporto al cliente.
                \end{itemize}
                
                In conclusione, una \texttt{temperature = 0.7} è una scelta equilibrata per molti scenari di generazione di testo quando si desidera che il modello produca risposte che sono né troppo rigide né eccessivamente libere, equilibrando tra la generazione di testo coerente e l'introduzione di elementi nuovi e creativi.

        \item
            \textbf{Top P}: Impostata a 0.9 per permettere una buona varietà di espressioni senza divagare troppo.

            \begin{itemize}
                \item Equilibrio tra casualità e coerenza: Con un \texttt{top\_p} di 0.9, si sta optando per un equilibrio tra generare testo che sia né troppo prevedibile né troppo casuale. È sufficientemente ristretto per mantenere la coerenza e la pertinenza del testo, ma abbastanza aperto per introdurre elementi creativi e variati.
        
                \item Controllo della diversità del testo: Questo valore permette al modello di esplorare diverse opzioni linguistiche senza deviare troppo dai modelli di lingua comuni o sensati. Il testo risultante tende ad essere interessante ma ancora legato alla realtà del contesto dato.
                \item Miglioramento della qualità del testo: L'uso di un \texttt{top\_p} elevato può migliorare la qualità del testo in scenari dove è richiesta una certa creatività senza perdere l'aderenza al contesto e alla logica del discorso.
            \end{itemize}
        
            In sintesi, \texttt{top\_p = 0.9} è una scelta che spesso rappresenta un buon compromesso per molti casi d'uso, specialmente quelli che richiedono un bilanciamento tra novità e coerenza del contenuto generato, come nella scrittura creativa, nel marketing, e in altre applicazioni di narrazione assistita dall'IA.
        
        \item
            \textbf{Lunghezza Massima}: Limitata a 150 token per mantenere le descrizioni abbastanza concise ma comunque consentire al modello un po' di spazio espressivo.
        
        \item
            \textbf{Sequenze di Stop}: Potrebbe essere ad esempio``\texttt{\#\#\#}'' o ``\texttt{</descrizione>}'' per segnalare chiaramente la fine di ciascuna descrizione.
        
        \item
            \textbf{Penalità di frequenza}: Si è detto che la penalità di frequenza controlla quanto un modello evita di ripetere le stesse parole di frequente; un valore più alto (es. 1.2) scoraggia maggiormente queste ripetizioni rispetto a un valore più basso (es. 0.5). È una sottile differenza di calibrazione.
            \begin{itemize}
                \item \textbf{Riduzione delle ripetizioni}: Applicando una penalità di 0.5, il modello tende a evitare di ripetere le stesse parole frequentemente nel testo, il che è utile per mantenere il contenuto fresco e interessante, specialmente in testi lunghi o in contenuti come articoli di blog, racconti o report informativi.
                
                \item \textbf{Maggiore variazione lessicale}: Questa impostazione incoraggia il modello a utilizzare sinonimi o frasi alternative, arricchendo il vocabolario del testo generato e migliorando la qualità complessiva del contenuto.
                
                \item \textbf{Equilibrio tra coerenza e creatività}: Una penalità di 0.5 è bilanciata in modo tale da non sopprimere completamente la ripetizione di termini tecnicamente importanti o di fraseologia necessaria per mantenere la coerenza del testo. Permette al modello di essere creativo ma anche coeso, evitando la generazione di testi che possono sembrare frammentati o eccessivamente dispersivi.
            \end{itemize}
        
            In conclusione, una \texttt{frequency\_penalty = 0.5} è una scelta efficace per chi cerca di bilanciare l'esigenza di varietà e freschezza nel testo con la necessità di mantenere una certa coerenza e rilevanza del contenuto.

        \item
            \textbf{Penalità di presenza}: Si è detto che la penalità di presenza invece riguarda invece la ripetizione di intere sequenze di token/frasi già viste in precedenza. Un valore negativo (es. -0.5) riduce la probabilità che il modello ripeta esattamente le stesse frasi, mentre un valore leggermente positivo (es. 0.1) minimizza in modo più lieve questa ripetizione di frasi meno frequenti.
            \begin{itemize}
                \item Incentiva la diversità: Una \texttt{presence\_penalty} moderata, come 0.2, aiuta a mantenere il testo vario senza deviare troppo dai temi o dagli argomenti trattati. Promuove la varietà ma mantiene un equilibrio, evitando che il testo diventi troppo dispersivo.
                    
                \item Riduce eccessive ripetizioni: Questo livello di penalità aiuta a prevenire la ripetizione eccessiva di termini o frasi, rendendo il testo generato più piacevole e professionale, particolarmente importante in contesti come la scrittura creativa, accademica o professionale.
                    
                \item Bilanciamento tra novità e coerenza: Con un \texttt{presence\_penalty = 0.2}, il modello è incoraggiato a introdurre nuovi contenuti mantenendo una connessione con il materiale già discusso, il che è cruciale per mantenere la coerenza del discorso senza cadere in ripetizioni monotone.
            \end{itemize}
        
            In conclusione, una \texttt{presence\_penalty = 0.2} è efficace per stimolare la diversità nel testo generato senza compromettere eccessivamente la coerenza o la pertinenza, rendendola una scelta equilibrata per molti contesti di generazione di testo automatico.
        \end{itemize}
        
        Questi parametri aiuterebbero a sfruttare le capacità linguistiche creative di GPT per produrre descrizioni di prodotto accattivanti, pur mantenendole concise, variate e conformi ai valori di allineamento mirato dell'azienda.
        
    \subsection{Esempio di interazione con le API GPT-3 in Python}
        Consideriamo ora in questo paragrafo un esempio come utilizzare questi parametri con le API di GPT-3 attraverso il linguaggio Python, che dovranno essere inclusi nella richiesta HTTP al servizio API di OpenAI.

        \begin{Verbatim}[frame=single]
import openai                  #importa la libreria OpenAI per
                               #interagire con l'API di GPT-3

response = openai.Completion.create(
    engine="text-davinci-003", #specifica il modello da utilizzare: "text-davinci-003"
                               #è uno dei modelli più avanzati disponibili
    prompt="Spiega i benefici dell'energia solare per le abitazioni residenziali.",
                               #fornisce il testo iniziale che guida il modello su
                               #cosa deve essere generato
    temperature=0.7,#0.7 promuove creatività senza diventare troppo imprevedibile
    max_tokens=150,	#numero massimo di token che il modello può generare come risposta
    top_p=0.9,      #si stanno includendo solo i token più probabili che, insieme,
       #accumulano il 90% della probabilità totale
    stop=["[The End]"],    	#sequenze di token che, se generate, fermano la
                           	#produzione di ulteriori token
    frequency_penalty=0.5,	#penalizza i token che appaiono più frequentemente,
                           	#riducendo la ripetitività
    presence_penalty=0.1 )	#penalizza i token ogni volta che compaiono,
                          	#incentivando la varietà
print(response.choices[0].text.strip()) #prende risposta generata dal modello
                                        #(response.choices[0].text), rimuove gli spazi
                                        #extra all'inizio e alla fine della stringa
                                        #(strip()) e la stampa.
        \end{Verbatim}

        Supponiamo ora di voler usare il codice per fare generare una breve storia; potrebbe essere:
        \\
        \textit{Dopo decenni di urbanizzazione sfrenata, la natura ha iniziato a reclamare il pianeta Terra. Le città, una volta simboli di progresso umano, ora giacevano abbandonate, avvolte da una fitta vegetazione. Al centro di quello che una volta era New York, un piccolo gruppo di sopravvissuti aveva trovato rifugio in un antico grattacielo, ora coperto di edera e radici. Avevano imparato a convivere con la natura, coltivando giardini verticali e raccogliendo l'acqua piovana per sopravvivere. Il loro leader, Mara, una volta ingegnere ambientale, guidava il gruppo con saggezza. ``La natura non è il nostro nemico,'' spiegava spesso, ``ma la nostra più grande alleata se impariamo a rispettarla.'' Con il passare degli anni, Mara e il suo gruppo stabilirono un equilibrio delicato con l'ambiente circostante, segnando l'inizio di una nuova era in cui umani e natura coesistevano in armonia. E così, nel cuore di una città riconquistata dal verde, germogliava la speranza per un futuro migliore. [The End]}
    
        Questo è un esempio del tipo di creatività e coerenza che ci si può aspettare con i parametri utilizzati. Ogni utilizzo del modello potrebbe produrre una storia leggermente diversa, grazie alla natura probabilistica del modello e configurazione dei parametri scelti.
        
    \subsection{Personalizzare attraverso piattaforme web}
        Le opzioni per personalizzare i parametri di un LLM come ChatGPT o Claude, usato attraverso piattaforme standard come i siti web di OpenAI o di Anthropic, sono generalmente limitate o non disponibili. La maggior parte delle personalizzazioni avanzate, come la temperatura, il Top P, la lunghezza massima e le penalità, non sono direttamente accessibili agli utenti finali in questa modalità di interazione.

        Nella versione di ChatGPT-3.5, si può però scegliere tra gli stili di conversazione
        \begin{itemize}
            \item Creativa,
            \item Bilanciata,
            \item Precisa,
        \end{itemize}
        ma i parametri specifici come temperatura, Top P e lunghezza massima non sono pubblicamente documentati da OpenAI per quanto riguarda i valori esatti utilizzati per ciascun stile.

        Questi stili di conversazione sono progettati per adattarsi a diverse esigenze e preferenze degli utenti senza che essi debbano gestire direttamente i parametri tecnici. OpenAI ha ottimizzato questi stili per garantire che, a seconda della scelta, il modello risponda in modo appropriato al contesto desiderato.

        È possibile comunque ipotizzare come questi stili potrebbero influenzare i parametri sulla base delle caratteristiche tipiche associate a ciascun stile: OpenAI ha ottimizzato questi stili.

        \begin{itemize}
            \item \textbf{Conversazione creativa}
            \begin{itemize}
                \item Temperatura: Probabilmente impostata su un valore più alto. La temperatura elevata aumenta la casualità delle risposte, permettendo al modello di generare risposte più uniche e meno prevedibili. Questo è ideale per compiti che richiedono creatività, come scrivere poesie, storie, o generare idee innovative.
                \item Top P: Probabilmente impostato su un valore relativamente alto per consentire una maggiore diversità nelle risposte e incoraggiare il modello a esplorare una varietà di possibili completamenti.
                \item Lunghezza massima: Potrebbe essere più flessibile per permettere sviluppi più estesi e creativi nelle risposte.
            \end{itemize}
            
            \item \textbf{Conversazione bilanciata}
            \begin{itemize}
                \item Temperatura: Probabilmente impostata su un valore medio. Questo equilibrio nella temperatura aiuta il modello a produrre risposte che sono né troppo prevedibili né troppo casuali, rendendolo adatto per la maggior parte delle applicazioni generali.
                \item Top P: Moderato, per mantenere una buona varietà nelle risposte ma senza deviare troppo in risposte troppo azzardate o irrilevanti.
                \item Lunghezza massima: Potrebbe essere configurata per produrre risposte di una lunghezza ragionevole, né troppo concise né troppo prolisse.
            \end{itemize}
            
            \item \textbf{Conversazione precisa}
            \begin{itemize}
                \item Temperatura: Impostata su un valore più basso. Una bassa temperatura rende le risposte del modello più deterministiche e concentrate, tendendo a scegliere le opzioni di completamento più probabili basate sui dati di addestramento.
                \item Top P: Più basso, per limitare la varietà delle risposte e focalizzarsi su quelle che sono più probabilmente accurate e informative, particolarmente utile per risposte basate su fatti o dati.
                \item Lunghezza massima: Potrebbe essere controllata per evitare divagazioni e mantenere le risposte concise e al punto.
            \end{itemize}
        \end{itemize}
        
    \subsection{Personalizzare Chat-GPT}
        Come utente finale di un LLM come ad esempio ChatGPT, con cui interagisco tramite il sito web di OpenAI, non si ha generalmente l'accesso diretto per modificare i parametri tecnici che influenzano la precisione o la creatività delle risposte. Tuttavia, si può indirettamente guidare il modello verso risposte più precise o creative attraverso tecniche di prompt engineering, cioè, formulare le domande nel modo più chiaro e dettagliato possibile per guidare le risposte del modello nella direzione desiderata.

        Vediamo brevemente alcune tecniche di formulazione del prompt, che riprendiamo e discutiamo nel dettaglio nel seguito di questo documento. Utilizzando questi approcci, si può spesso ottenere risposte che si avvicinano ai nostri obiettivi di precisione o creatività.

        \begin{itemize}
            \item \textbf{Per incoraggiare risposte più creative}:
            \begin{itemize}
                \item Chiedere di pensare fuori dagli schemi: Puoi incoraggiare il modello a essere più creativo con prompt che invitano a esplorazioni imaginarie. Ad esempio, \textit{``Immagina un mondo dove gli alberi possono parlare. Come sarebbe una giornata tipica?''}

                \item Usare prompt aperti: I prompt aperti permettono al modello di esplorare una gamma più ampia di possibilità. Ad esempio, \textit{``Cosa succederebbe se la gravità sulla Terra fosse improvvisamente dimezzata?''}.
                
                \item Chiedere di creare storie o scenari: Chiedere a ChatGPT di inventare una storia o descrivere uno scenario immaginario può portare a risposte molto creative. Ad esempio, ``\textit{Racconta una storia su un viaggio nello spazio che scopre un nuovo pianeta abitabile.''}
            \end{itemize}

            \item \textbf{Per incoraggiare risposte più precise:}
            \begin{itemize}
                \item Essere specifici: Specifica chiaramente ciò che desideri sapere. Ad esempio, invece di chiedere \textit{``Raccontami qualcosa su Marte''}, potresti chiedere \textit{``Quali sono le ultime scoperte scientifiche fatte dal rover Perseverance su Marte?'}'

                \item Usare domande chiuse (quando possibile): Le domande chiuse tendono a limitare lo spazio di risposta del modello, rendendole più dirette e concentrate. Ad esempio, \textit{``Marte ha atmosfera?''} è più diretto rispetto a \textit{``Cosa puoi dirmi dell'atmosfera di Marte?''}
                
                \item Chiedere definizioni o spiegazioni dettagliate: Se cerchi informazioni precise, chiedere definizioni o spiegazioni dettagliate può aiutare. Ad esempio, \textit{``Puoi spiegare come funziona la fotosintesi nei dettagli?'}'
            \end{itemize}
        \end{itemize}

        A quanto detto fino ad ora, possiamo applicare delle \textbf{strategie generali}:
        \begin{itemize}
            \item Fornire contesto: Aggiungere dettagli o contesto al tuo prompt può aiutare il modello a capire meglio il livello di creatività o precisione che stai cercando.

            \item Iterare sui prompt: Se la prima risposta non soddisfa le tue aspettative, puoi riformulare il prompt o chiedere chiarimenti per guidare il modello verso la direzione desiderata.
        \end{itemize}

    \subsection{Principi e tecniche di prompt engineering}
        Il prompt engineering gioca un ruolo cruciale nel guidare i modelli di linguaggio verso output desiderati. I prompt funzionano come istruzioni testuali che forniscono al modello il contesto per interpretare la richiesta e generare risposte adeguate. La precisione e chiarezza dei prompt sono fondamentali per evitare ambiguità e indirizzare il modello verso informazioni rilevanti. Tecniche come definire il contesto, specificare vincoli, usare parole chiave strategiche e impostare il tono aiutano a ottimizzare i prompt. Il prompting costituzionale incorpora principi etici espliciti da seguire. Approcci come lo one-shot learning, il few-shot learning e il chain of thought prompting migliorano le capacità di ragionamento del modello. Infine, la lingua utilizzata nei prompt influenza aspetti come la complessità linguistica, il contesto culturale e potenziali bias.

        \subsubsection{Come funzionano i prompt}
            Il prompt engineering gioca un ruolo cruciale nella modulazione e guida delle risposte dei modelli di linguaggio avanzati. Questo processo consiste nel formulare input specifici (prompt) che indirizzano il modello verso la produzione di output desiderato.

            I \textbf{prompt} funzionano come istruzioni testuali che un utente inserisce nel modello di linguaggio che utilizza le informazioni fornite (contenute nel prompt) per interpretare cosa l'utente sta cercando e per generare una risposta adeguata (in linea con le aspettative dell'utente).
            
            Vediamo quindi come funzionano i prompt, riprendendo anche quanto già introdotto discutendo dei ``Large Language Models'':

            \begin{enumerate}
                \item \textbf{Interpretazione del prompt}: Quando un prompt viene inserito in un modello di linguaggio, il primo passo del modello è analizzare e interpretare questo input. I modelli di linguaggio avanzati, come GPT, BERT, Claude, ecc. utilizzano tecniche NLP per decompore il testo del prompt in componenti comprensibili (token). Questo processo di tokenizzazione consente al modello di comprendere le parole e le frasi nel loro contesto.
                
                \item \textbf{Rappresentazione interna}: Dopo la tokenizzazione, il modello trasforma le parole in vettori numerici, che sono rappresentazioni matematiche in uno spazio vettoriale. Questi vettori catturano non solo il significato delle parole, ma anche le loro relazioni con altre parole nel contesto del prompt. Questa trasformazione in embedding permette al modello di manipolare linguisticamente le informazioni in maniera efficiente.
                
                \item \textbf{Generazione del testo}: Utilizzando gli ``embedding'' e la propria architettura interna (come i layer di attenzione nei modelli Transformer), il modello predice quale dovrebbe essere la risposta più probabile e rilevante basata sul prompt. Questo è ottenuto attraverso un processo di selezione delle parole successive fino al completamento di una frase o paragrafo che il modello ritiene sia la conclusione logica del prompt.
                
                \item \textbf{Risposta al prompt}: Infine, il testo generato viene presentato all'utente come risposta al prompt iniziale. Questa risposta è il risultato delle previsioni del modello su cosa dovrebbe seguire logicamente dall'input fornito dall'utente.
            \end{enumerate}
                
            Supponiamo ora che l'utente inserisca il prompt: \textit{``Descrivi il processo di fotosintesi.''}, e discutiamo con maggiore dettaglio come il modello procederebbe secondo lo schema appena definito.
            
        \subsubsection{Interpretazione dei prompt}
            Il primo passo è tokenizzare il prompt in componenti comprensibili. Ad esempio, il nostro prompt potrebbe essere tokenizzato come:

            \texttt{["Descrivi", "il", "processo", "di", "fotos", "\#\#intesi"]}.
            
            Si potrebbe dire che in questa fase ``il modello comprende che si sta chiedendo una spiegazione scientifica'', ma occorre chiarire meglio questo aspetto che riguarda il modo in cui i modelli di linguaggio comprendono il contesto dei prompt in modo implicito, piuttosto che attraverso una comprensione simbolica esplicita.
            
            Durante la fase di interpretazione del prompt \textit{``Descrivi il processo di fotosintesi''}, il modello non riconosce in modo dichiarativo che gli viene chiesta una spiegazione scientifica. Non c'è una classificazione o rappresentazione interna dedicata al concetto di \textit{``spiegazione scientifica''}. Tuttavia, il modello è in grado di inferire il tipo di risposta richiesta da diversi segnali contestuali presenti nel prompt:
            \begin{itemize}
                \item \textbf{Vocabolario specialistico}: Parole come ``processo'' e ``fotosintesi'' fanno parte del linguaggio scientifico e forniscono indicazioni che la risposta dovrebbe essere di tipo tecnico/esplicativo.
            
                \item \textbf{Pattern linguistici}: Nell'enorme quantità di dati su cui è stato addestrato, il modello ha incontrato molte istanze di domande come ``Descrivi il processo di X'' seguite da spiegazioni dettagliate. Questo pattern associa implicitamente tali frasi a risposte esplicative.
            
                \item \textbf{Conoscenza pregressa}: Sebbene non ``comprenda'' il concetto ``fotosintesi'' a livello simbolico, il modello ha sviluppato una conoscenza distribuita sul tema durante la fase di training, associandolo statisticamente a nozioni sui processi biologici e chimici delle piante.
            
                \item \textbf{Ragionamento contestuale}: Man mano che inizia a generare una risposta del tipo spiegazione scientifica, questa direzione diventa sempre più ``raccomandata'' dal modello sulla base della coerenza con il prompt e il contesto generato finora.
            \end{itemize}
            
            In sostanza, pur senza una rappresentazione dichiarativa di ``spiegazione scientifica'', numerosi segnali contestuali impliciti guidano il comportamento del modello in tale direzione, grazie alla enorme quantità di conoscenza incorporata attraverso il training su vasti dati di testo. È un'abilità di ragionamento implicito ed emergente, piuttosto che un processo di comprensione simbolica esplicita.
            
        \subsubsection{Embedding}
            Un embedding, nel contesto dell'interpretazione di un prompt, è una rappresentazione vettoriale (una sequenza di numeri) dei tag del prompt in uno spazio ad alta dimensione. Il processo di creazione di un embedding avviene tipicamente attraverso l'utilizzo di modelli di embedding pre-addestrati, come word2vec, GloVe o BERT. Questi modelli sono stati addestrati su enormi quantità di testo per imparare a mappare le parole e le frasi in rappresentazioni vettoriali in modo tale che parole che appaiono frequentemente in contesti simili o frasi simili siano mappate in vettori vicini nello spazio vettoriale. Tali modelli hanno già mappato milioni di parole in vettori di numeri (di solito da 100 a 300 dimensioni).

            Questa rappresentazione vettoriale cattura le relazioni semantiche e sintattiche tra le parole nel testo, principalmente attraverso un approccio statistico basato sui dati utilizzati durante l'addestramento, permettendo ai modelli NLP di comprendere meglio il significato del prompt.
            
            Ad esempio, se le parole ``fotosintesi'' e ``clorofilla'' appaiono spesso vicine nello stesso contesto in molti testi, il modello impara che queste parole sono semanticamente correlate e assegnerà loro embedding vettoriali simili e vicini nello spazio vettoriale. Inoltre, i modelli possono anche catturare relazioni sintattiche simili esaminando schemi grammaticali ricorrenti. Ad esempio, parole che svolgono ruoli sintattici simili in molte frasi tenderanno ad avere embedding simili.
            
            Questo apprendimento delle relazioni semantiche e sintattiche, come già detto, è però puramente statistico e basato sui dati. Non c'è una comprensione ``profonda'' del significato delle parole, ma semplicemente un'associazione statistica dei contesti in cui appaiono parole simili. Più dati di addestramento vengono forniti al modello, migliori saranno le relazioni catturate negli embedding risultanti. È un processo di apprendimento non supervisionato che sfrutta le enormi quantità di dati di testo disponibili.
            
        \subsubsection{Apprendimento non supervisionato e supervisionato}
            \begin{itemize}
                \item
                    Apprendimento non supervisionato: tecnica di machine learning in cui l'algoritmo cerca di individuare autonomamente pattern e relazioni nei dati in input, senza essere fornito di esempi o etichette di addestramento precostituiti.

                    Esempio: Supponiamo di avere un dataset di clienti di un negozio con informazioni come età, reddito, stato civile, ecc. Un algoritmo di clustering non supervisionato potrebbe analizzare questi dati e raggruppare automaticamente i clienti in cluster omogenei in base alle loro caratteristiche simili, senza che gli fossero forniti in precedenza etichette o gruppi predefiniti. Questo permetterebbe di individuare segmenti di clientela con profili e preferenze simili per strategie di marketing mirate. L'algoritmo impara a riconoscere pattern e raggruppamenti nei dati in modo autonomo, senza alcuna supervisione o etichette fornite.

                \item
                    Apprendimento supervisionato: tecnica di machine learning in cui l'algoritmo viene addestrato su un dataset di esempi etichettati, in modo da imparare a mappare gli input alle corrette output desiderate.
            
                    Esempio: Supponiamo di avere un dataset di immagini di cani e gatti, dove ogni immagine è etichettata con ``cane'' o ``gatto''. Un algoritmo di apprendimento supervisionato, come una rete neurale, può essere addestrato su questo dataset etichettato. Durante l'addestramento, l'algoritmo impara a riconoscere le caratteristiche distintive dei cani e dei gatti dalle immagini di esempio e dalle relative etichette fornite.
                    
                    Una volta addestrato, quando gli viene mostrata una nuova immagine, l'algoritmo sarà in grado di classificarla correttamente come ``cane'' o ``gatto'', avendo imparato a riconoscere i pattern rilevanti dai dati di addestramento etichettati in precedenza. In questo caso, la ``supervisione'' viene data dalle etichette ``cane'' e ``gatto'' associate alle immagini di addestramento, che guidano l'algoritmo ad apprendere il mapping corretto tra input (immagini) e output (etichette).
            \end{itemize}

            In sostanza, gli embedding riassumono le relazioni statistiche tra parole osservate in vasti corpora di testo in modo denso e compresso, consentendo ai modelli di elaborazione del linguaggio naturale di sfruttare queste ricche informazioni contestuali.
            
            Una volta che un prompt è stato convertito in un embedding vettoriale, questo può essere utilizzato come input per altri modelli di apprendimento automatico o di NLP.
            
            Ad esempio, nel caso di un modello di generazione di testo come GPT, l'embedding del prompt viene fornito al modello per aiutarlo a comprendere il contesto e il significato del prompt, in modo da generare un output di testo coerente e rilevante.
            
    \subsection{Rappresentazione interna}
        Dopo la fase di interpretazione passiamo alla fase successiva in cui andiamo a creare una rappresentazione interna del token e che potremmo definire anche come analisi del contesto. Durante tale fase, ogni token viene trasformato in un embedding, cioè un vettore numerico che cattura il suo significato e le relazioni con gli altri token nel contesto. Dopo aver tokenizzato il prompt, la parola ``fotosintesi'' è stata suddivisa in due token: ``fotos'' e ``\#\#intesi''. Supponiamo di usare un modello di embedding come Word2Vec pre-addestrato; l token potrebbero essere mappati come segue (questi sono solo esempi di vettori casuali per semplificare):
        \begin{itemize}
            \item ``fotos'' potrebbe essere mappato in un vettore simile a: \texttt{[-0.23, 0.15, -0.08, 0.32, ..., 0.11]}
            \item ``\#\#intesi'' potrebbe essere mappato in un vettore simile a: \texttt{[0.18, -0.21, 0.04, -0.15, ..., -0.09]}
        \end{itemize}
        
        Il vettore embedding finale per la parola ``fotosintesi'' viene tipicamente ottenuto combinando in qualche modo i vettori dei suoi token costituenti ``fotos'' e ``\#\#intesi''; Un approccio comune è fare la media dei vettori dei token. Quindi l'embedding finale per:
        \begin{itemize}
            \item ``fotosintesi'' potrebbe essere: \texttt{[-0.025, -0.03, -0.02, 0.085, ..., 0.01]}
        \end{itemize}
        
        Tale vettore rappresenta la ``codifica'' semantica della parola ``fotosintesi'' in uno spazio vettoriale denso. Parole simili, come ``clorofilla'' o ``processo biologico'', avranno embedding vicini nello spazio vettoriale. Questo embedding cattura il significato della parola e può essere utilizzato da modelli NLP per comprendere meglio il prompt originale.
        
        Facciamo un ulteriore esempio: “valutare se recensioni di ristoranti (ogni recensione è un testo) è positiva o negativa, in modo da poterli consigliare o meno”.
        
        A tale scopo, possiamo convertire ogni recensione in un embedding che catturi il “significato” e il sentimento complessivo della recensione. Ad esempio, recensioni come:
        \begin{itemize}
            \item ``Il servizio era lento e il cibo era insipido'' potrebbe essere convertita in \texttt{[0.2, -0.7, -0.1, ...]},
            \item ``Cibo delizioso e personale cordiale'' potrebbe essere convertita in	\texttt{[0.8, 0.6, 0.3, ...]}.
        \end{itemize}
        
        Facciamo notare che nel caso di recensioni positive, come la seconda recensione, notiamo embedding con valori numerici più alti, mentre quelle negative hanno valori più bassi. Questo perché le parole positive come ``delizioso'' e ``cordiale'' sono mappate a vettori con valori più alti. Ora, con questi embedding numerici, un modello di apprendimento automatico può facilmente imparare a distinguere le recensioni positive da quelle negative, semplicemente guardando ai valori nell'embedding.
        
        Quindi, in poche parole, attraverso questo processo di embedding converte testo in numeri, creando una rappresentazione interna dei token in modo che un computer possa facilmente elaborarli e capirne il significato complessivo.

    \subsection{Generazione del testo}
        Utilizzando gli embedding del prompt come input, il modello utilizza la sua architettura a Transformer per generare un embedding per il token successivo più probabile da aggiungere al testo da generare. Questo embedding è poi mappato alla parola corrispondente dal vocabolario. Ad esempio, potrebbe prevedere che dopo ``Descrivi il processo di fotosintesi'', la parola successiva più probabile è ``La''. Quindi genera l'embedding per ``La'' e lo aggiunge all'output parziale. Questo processo si ripete, con il modello che preleva il contesto del prompt e dell'output parziale generato per prevedere i token successivi, fino a completare una descrizione coerente del processo di fotosintesi.

        Abbiamo visto come, per ogni token, viene recuperato o calcolato il suo embedding vettoriale basato su un modello di embedding pre-addestrato; gli embedding dei singoli token vengono combinati (ad es. facendone la media) per ottenere un singolo embedding vettoriale rappresentativo dell'intero prompt fornito come input iniziale per un modello di generazione di testo come, ad esempio, GPT.
        
        Il modello GPT utilizza l'embedding per catturare il contesto e il significato generale del prompt.
        
        Quindi il modello inizia a generare token dopo token la nuova sequenza di output, prevedendo la parola successiva più probabile data l'embedding del prompt e le parole generate fino a quel momento.
        
        Ad ogni passo, quindi, il nuovo token generato viene incorporato per calcolare un nuovo embedding contestuale aggiornato; questo embedding aggiornato viene quindi utilizzato per la previsione del token successivo, e così via fino al completamento dell'output generato.
        
        Quindi in sostanza, l'embedding iniziale del prompt fornisce il contesto semantico di partenza, e poi il modello genera testo mantenendo una rappresentazione densa del contesto emergente mentre produce l'output token per token. Gli embedding permettono quindi di catturare il significato e guidare la generazione di testo coerente e rilevante per il prompt iniziale.
        
        Questo è il flusso generale, ma ci sono poi molti dettagli architetturali e di training specifici ai diversi modelli di generazione di testo.
    
        \subsubsection{Punti di attenzione}
            Vediamo alcuni dettagli più specifici su come gli embedding vengono utilizzati in modelli di generazione di testo come GPT (su cui è basato Claude).

            Abbiamo descritto come gli embedding sono vettori densi rappresentanti i singoli token di input, e che vengono appresi durante il pre-addestramento su vasti corpora di testo, insieme ai pesi del modello trasformatore. Gli embedding non sono però semplicemente lookup statici, ma vengono ulteriormente trasformati passandoli attraverso alcuni “punti di attenzione” nel trasformatore. Questo permette al modello di specializzarli per compiti specifici durante il processo di fine-tuning.
            
            Nel caso di Claude, gli embedding iniziali vengono calcolati sul prompt tokenizzato in input. Vengono poi passati ai punti di attenzione del trasformatore decoder, insieme ad uno speciale token di embedding per indicare l'inizio della generazione.
            
            Ad ogni passo di generazione, il decoder produce una distribuzione di probabilità sui possibili token successivi, date le rappresentazioni interne del contesto corrente (che includono gli embedding). Il token più probabile viene campionato e aggiunto all'output.
            
            Gli embedding del nuovo token vengono incorporati alle rappresentazioni del contesto, influenzando la generazione del token successivo. Questo processo si ripete ricorsivamente per generare l'intero output una parola alla volta.
            
            I punti di attenzione permettono al modello di fondere informazioni dagli embedding passati e futuri, costruendo rappresentazioni ricche di contesto per la generazione coerente.
            
            Claude utilizza anche delle regolazioni come il campionamento top-p per controllare la casualità dell'output rispetto alla massima verosimiglianza.
            
            Gli embedding e le loro trasformazioni all'interno del modello sono la chiave per catturare e propagare il significato contestuale durante la generazione, guidando l'output ad essere rilevante e coerente con il prompt. Questo processo iterativo di encoding/decoding degli embedding è fondamentale per GPT e modelli simili.
            
             I ``punti di attenzione'' (attention heads) sono un componente architetturale fondamentale all'interno dei modelli Trasformatori come quelli utilizzati da GPT e Claude, e fanno parte del meccanismo di auto-attenzione nei trasformatori. Ogni testa di attenzione è essenzialmente una funzione che mappa un vettore di query con le chiavi (keys) e i valori (values) provenienti dagli stati precedenti del modello. Questo consente al modello di concentrarsi sulle parti più rilevanti dell'input a ogni passo.
            
            Più specificamente, in un livello di attenzione ci sono tipicamente diversi punti di attenzione parallele (ad es. 8 o 16 punti). Ognuna impara a concentrarsi su diverse relazioni all'interno dei dati. L'output dei punti viene poi combinato attraverso un'operazione di concatenazione seguita da una trasformazione lineare.
            
            Quindi i punti di attenzione svolgono un ruolo cruciale nel consentire al modello di modellare efficacemente le dipendenze a lungo raggio nel testo e combinare informazioni da diverse posizioni dell'input in modo flessibile.
            
            E importante precisare che le punti di attenzione sono distinte dal concetto di ``top-p sampling'', introdotto in precedenza, che è una tecnica di campionamento utilizzata durante l'effettiva generazione di token di output, e che permette di aumentare la varietà dell'output rispetto al semplice campionamento dalla parola più probabile.
            
            Quindi le punti di attenzione sono parti integranti dell'architettura del modello volte a catturare le dipendenze di input, mentre il top-p è una tecnica di campionamento aggiuntiva applicata durante l'effettiva generazione di testo. Sono concetti e meccanismi diversi ma complementari all'interno di questi modelli linguistici.
            
        \subsubsection{Fine tuning}
            Ulteriore precisazione è riferita al fine-tuning (adattamento fine), tecnica comunemente utilizzata quando si adoperano LLM come GPT per compiti specifici, e che consiste nel seguente processo:
            \begin{enumerate}
                \item Si parte da un modello pre-addestrato su un'enorme quantità di dati di testo generico (come GPT originale addestrato da OpenAI). Questo pre-addestramento apprende embedding di parole, pesi delle punti di attenzione, ecc. in modo non supervisionato.

                \item Si applica un ulteriore addestramento supervisionato su un dataset specifico per il compito desiderato (ad es. risposte a domande, riepilogo di testi, ecc). Durante questo fine-tuning, la maggior parte dei parametri del modello rimangono gli stessi dal pre-addestramento generico.

                \item Però, gli ultimi strati del modello (di solito il cosiddetto layer normalization e il layer di output) vengono effettivamente ritarati dall'inizio in modo supervisionato sui dati del compito specifico.

                \item Alcuni dei parametri del modello pre-addestrato vengono leggermente aggiornati (``fine-tuned'') per adattarsi meglio ai nuovi dati del compito. Questo fine-tuning permette di sfruttare l'apprendimento precedente del modello sui dati generici, trasferendo quelle conoscenze di base sul linguaggio al nuovo compito. Soltanto una piccola porzione dei parametri viene effettivamente riaddestratta in modo significativo.
            \end{enumerate}
            
            Il risultato è un modello ``specializzato'' per uno scopo specifico, che mantiene però la maggior parte delle capacità di modellazione del linguaggio acquisite durante il pre-addestramento generico su larga scala.
            
            Nel caso di Claude, il fine-tuning conversazionale svolto da Anthropic gli permette di applicare le sue vaste conoscenze di base all'interazione e generazione di risposte rilevanti per l'utente.
            
            I LLM come GPT e Claude tipicamente hanno un'architettura di rete neurale molto profonda, composta da decine di ``layer'' o strati. Nello specifico:
            \begin{itemize}
                \item GPT-2, aveva 48 strati (layer) di codificatori trasformatori.
                
                \item GPT-3, l'attuale modello di punta di OpenAI, ha una versione con 96 strati per il modello più grande.
                
                \item Claude: i dettagli dell'architetture non sono resi pubblici, ma essendo basato su GPT, si può supporre abbia un numero simile di decine di strati.
            \end{itemize}
            
            Ogni strato tipicamente contiene un sottoinsieme dei punti di attenzione multi-head, menzionate prima, insieme ad operazioni di normalizzazione dei dati e connessioni residuali che collegano gli strati.
            
            Questa profondità permette ai modelli di catturare pattern linguistici sempre più astratti e complessi mentre le informazioni fluiscono attraverso la rete. I primi strati tendono a elaborare aspetti più superficiali come le singole parole, mentre gli strati più profondi costruiscono rappresentazioni più ricche del significato e del contesto.
            
            Quindi in sintesi, mentre non si conoscono esattamente i dettagli di Claude, possiamo supporre che abbia un'architettura molto profonda con probabilmente 50-100 strati di codificatori e decodificatori trasformatori, in linea con le dimensioni e le capacità di GPT-3.
            
            Questa profondità di strati è una delle chiavi che permette a questi grandi modelli di linguaggio di raggiungere prestazioni così impressionanti su una vasta gamma di compiti linguistici complessi.
            
    \subsection{Risposta al prompt}
        Il modello di generazione di testo, come GPT o Claude, non produce direttamente il testo di output finale in una forma facilmente leggibile. Piuttosto, genera una sequenza di token di output, che sono essenzialmente degli id numerici che rappresentano ogni parola/elemento di testo nel vocabolario del modello. Ad esempio, la sequenza di output del modello per la descrizione della fotosintesi potrebbe essere una lista di numeri come: \texttt{[827, 9132, 321, 57, 103, 9876, ...]}, Dove ogni numero corrisponde al token di una parola specifica come ``La'', ``fotosintesi'', ``è'', ``il'', ecc. nel vocabolario del modello. Quindi ciò che viene effettivamente ``fornito'' alla fase di output non è testo, ma questa sequenza di id di token numerici. A questo punto la fase di output deve quindi:
        \begin{itemize}
            \item Decodificare questa sequenza di id numerici utilizzando il vocabolario o il dizionario incorporato del modello per ottenere la sequenza di token testuali effettivi (parole).
        
            \item Unire questi token testuali in una singola stringa di testo coerente, rimuovendo eventuali caratteri speciali di tokenizzazione.
        
            \item Applicare eventuali regole di formattazione aggiuntive come punteggiatura, maiuscole/minuscole, ecc.
        
            \item Renderizzare e visualizzare questa stringa di testo finale nell'interfaccia desiderata, ad esempio una interfaccia di chat di conversazione come ChatGPT o Claude, producendo nel nostro esempio:
        \end{itemize}

        ``La fotosintesi è il processo attraverso il quale le piante convertono l'anidride carbonica e l'acqua in ossigeno e zuccheri utilizzando l'energia della luce solare...''
        
        La chiave è che l'output del modello di generazione è un flusso di token predetti che devono poi essere opportunamente renderizzati come testo, audio, immagini o qualsiasi altro formato a seconda dell'applicazione finale. Ma il processo fondamentale riguarda la generazione token per token guidata dagli embedding iniziali del prompt.
        
        In estrema sintesi, i prompt funzionano come catalizzatori che guidano il processo di generazione di testo nei modelli di linguaggio, permettendo agli utenti di ottenere informazioni specifiche, risposte a domande, o qualsiasi altro tipo di comunicazione testuale desiderata.
        
        \subsubsection{Esempi}
            Nel seguito vengono riportati alcuni esempi pratici che illustrano come il prompt engineering può modulare e guidare le risposte dei modelli di linguaggio avanzati, fornendo input specifici che direzionano il modello verso la produzione dell'output desiderato.
            \begin{enumerate}
                \item Assistente virtuale per il servizio clienti per risolvere le richieste di assistenza in modo efficiente.
                \begin{itemize}
                    \item Prompt inefficace: ``Aiutami.''
                    
                    \item Prompt migliorato: ``Sono un cliente che ha acquistato una fotocamera [specificare il modello preciso] ieri e non riesce a trovare il manuale d'uso nel pacco. Potresti inviarmi un link al manuale digitale?''
                    
                    \item Spiegazione: Il prompt migliorato fornisce dettagli specifici sul problema del cliente e sulla richiesta, guidando il modello a fornire una risposta precisa e direttamente utile, come il link al manuale d'uso, invece di rispondere in modo generico.
                \end{itemize}

                \item Generazione di contenuti per blog per creare articoli di blog pertinenti e informativi.
                \begin{itemize}
                    \item Prompt inefficace: ``Scrivi un articolo.''
                    
                    \item Prompt migliorato: ``Crea un articolo di 800 parole che esplori le implicazioni della realtà aumentata nella formazione medica, includendo statistiche recenti e esempi di applicazioni reali.''
                    
                    \item Spiegazione: Questo prompt specifica il tema dell'articolo, la lunghezza desiderata, e gli elementi che dovrebbero essere inclusi come le statistiche e gli esempi pratici. Il modello è così indirizzato a produrre un contenuto mirato e dettagliato che soddisfa i requisiti dati.
                \end{itemize}

                \item Supporto educativo per fornire spiegazioni comprensibili su concetti complessi.
                \begin{itemize}
                    \item Prompt inefficace: ``Parlami della teoria della relatività.''
                    
                    \item Prompt migliorato: ``Puoi spiegare la teoria della relatività e i suoi effetti sui viaggi spaziali a uno studente di liceo interessato all'astrofisica?''
                    
                    \item Spiegazione: Il prompt migliorato specifica il pubblico target (studente di liceo) e un contesto applicativo specifico (viaggi spaziali), permettendo al modello di adattare il livello di complessità e focalizzare la spiegazione su aspetti rilevanti del soggetto.
                \end{itemize}

                \item Contesto di sviluppo Web per guidare l'utente nella creazione di una pagina Web.
                \begin{itemize}
                    \item Prompt inefficace: ``Dimmi come usare HTML e CSS.''
                    
                    \item Problema: Questa richiesta è molto generica e non specifica quali aspetti di HTML e CSS l'utente vuole imparare. Non fornisce informazioni sul livello di esperienza dell'utente o su quali obiettivi specifici ha in mente.
                    
                    \item Prompt migliorato: ``Potresti mostrarmi come creare una layout di pagina web con una barra di navigazione in alto e un'intestazione centrata, usando HTML5 e CSS3 per un principiante?''
                    
                    \item Miglioramento: Questo prompt è molto più specifico e fornisce dettagli che aiutano a capire esattamente cosa l'utente vuole imparare. Include anche il livello di esperienza dell'utente (principiante), consentendo di adattare la risposta al suo livello di conoscenza.
                    
                    \item Spiegazione: Il prompt migliorato guida il modello o l'istruttore a fornire una risposta che è direttamente rilevante per le esigenze immediate dell'utente. Questo non solo rende la comunicazione più efficiente ma assicura anche che l'utente riceva istruzioni che può seguire e applicare direttamente. Inoltre, specificando che si tratta di HTML5 e CSS3, il prompt chiarisce che le tecniche dovrebbero essere moderne e aggiornate.
                \end{itemize}

                \item Troubleshooting -- Nell'ambito di progetti e problemi legati a specifiche apparecchiature, un'efficace formulazione del prompt può fare una grande differenza nel ricevere una guida specifica e utile. Ecco un esempio che fa riferimento ad Arduino.
                \begin{itemize}
                    \item Prompt inefficace: ``Il mio progetto Arduino non funziona.''
                    
                    \item Problema: Questa richiesta è troppo vaga. Non fornisce dettagli sul tipo di progetto, la natura del problema, né su cosa l'utente ha già provato per risolverlo.
                   
                    \item Prompt migliorato: ``Sto lavorando su un progetto Arduino che utilizza un sensore di temperatura (modello TMP36) per attivare un LED quando la temperatura supera i 25°C. Ho caricato lo sketch sul mio Arduino Uno, ma il LED rimane acceso tutto il tempo, indipendentemente dalla temperatura. Ho controllato le connessioni e sembrano corrette. Potresti aiutarmi a capire perché il LED non si spegne?''
                    
                    \item Miglioramento: Questo prompt è molto più dettagliato e fornisce informazioni specifiche sul progetto, sul comportamento atteso e su quello effettivo, e sulle azioni che l'utente ha già intrapreso per tentare di risolvere il problema.
                    
                    \item Spiegazione: Il prompt migliorato è utile per diverse ragioni:
                    \begin{itemize}
                        \item Contesto specifico: Include dettagli sui componenti usati (Arduino Uno, sensore TMP36), permettendo di identificare potenziali problemi specifici di tali componenti.
            
                        \item Descrizione del problema: Descrive chiaramente il problema osservato (LED sempre acceso) e il comportamento atteso (LED che si accende solo oltre i 25°C), che aiuta a focalizzare la risposta sulle possibili cause di questo comportamento.
                        
                        \item Azione precedente: Informa che le connessioni sono state controllate, il che aiuta a escludere una causa comune di problemi nei progetti Arduino.

                        \item Questo tipo di prompt consente a chi risponde (sia esso un umano o un sistema AI) di offrire soluzioni più mirate e utili, riducendo il tempo necessario per arrivare a una soluzione efficace. Aiuta anche a evitare suggerimenti di base che l'utente ha già provato, ottimizzando così il processo di troubleshooting.
                    \end{itemize}
                \end{itemize}
            \end{enumerate}
            
            
            Questi esempi dimostrano come un'efficace progettazione del prompt possa influenzare direttamente la qualità e la pertinenza delle risposte generate da un modello di linguaggio, rendendole più utili e adatte alle necessità dell'utente.
            
            Implementando questi approcci, è possibile migliorare significativamente l'interazione tra l'utente e i modelli di IA, trasformando gli input generici in risposte specifiche e ben direzionate.
            
            Applicando i principi del prompt engineering anche alle richieste di aiuto o istruzioni in contesti tecnici come la programmazione o la risoluzione di problemi, possiamo migliorare significativamente l'efficacia delle risposte fornite, rendendo l'apprendimento più rapido e mirato.
            
    \subsection{Prompt impliciti e prompt espliciti}
        Vediamo ora in questo paragrafo cosa si intende e come applicare correttamente la distinzione tra prompt impliciti ed espliciti al fine di utilizzare i modelli di linguaggio in modo più efficace, adattandoli agli obiettivi specifici e al contesto di utilizzo, migliorando l'interazione tra l'utente e il modello e aumentando anche la probabilità di ottenere risposte utili e pertinenti.
        
        \subsubsection{Prompt impliciti}
            Input forniti a un modello di linguaggio che suggeriscono una risposta o un tipo di risposta senza specificare esplicitamente i dettagli esatti di cosa debba essere incluso nella risposta; lasciano maggiore spazio interpretativo al modello, permettendo una certa flessibilità nella generazione del testo e spesso stimolando risposte più creative o elaborate. Loro caratteristiche sono quelle di essere:
            \begin{itemize}
                \item \textbf{Meno direttivi}: Non danno istruzioni specifiche su come formulare la risposta.
                
                \item \textbf{Aperti}: Consentono al modello di utilizzare il proprio ``giudizio'' basato sull'addestramento ricevuto per decidere come meglio rispondere.
                
                \item \textbf{Flessibili}: Possono portare a una varietà di tipi di risposte, a seconda di come il modello interpreta il prompt.
                
                \item \textbf{Creativi}: Stimolano risposte più creative e meno vincolate da formati rigidi.
            \end{itemize}
            
        \subsubsection{Esempio di prompt implicito}
            Un insegnante vuole generare materiale didattico su Shakespeare: \textit{``Parlami di Shakespeare.''} È un esempio di prompt implicito perché:
            \begin{itemize}
                \item \textbf{Non specifica il formato della risposta}: Il modello può decidere se fornire biografia dettagliata, analisi delle opere più famose, riassunto di un particolare pezzo teatrale, ecc.
                
                \item \textbf{Non impone un argomento specifico}: Il modello ha la libertà di selezionare da un'ampia gamma di argomenti correlati a Shakespeare: sua importanza nella letteratura inglese, influenza culturale delle sue opere, dettagli specifici su una delle tragedie o commedie …
                
                \item \textbf{Aperto a diverse interpretazioni}: A seconda di come il modello è stato addestrato e dei dati su cui è stato addestrato, potrebbe focalizzarsi su aspetti diversi della vita o delle opere di Shakespeare, mostrando come diversi modelli possono interpretare lo stesso prompt in modi diversi.
            \end{itemize}

            L'utilizzo di prompt impliciti può essere particolarmente utile quando si desidera esplorare la capacità di un modello di generare risposte informative e creative basate su una comprensione generale del contesto, senza vincoli rigidi su come quelle informazioni dovrebbero essere presentate.
            
        \subsubsection{Prompt espliciti}
            Input testuali forniti ai modelli di linguaggio che specificano in modo esplicito tipo, formato o contenuto della risposta desiderata; sono direttivi e lasciano al modello poco spazio di interpretazione, guidando la generazione della risposta in una direzione precisa. Loro caratteristiche sono quelle di essere:
            \begin{itemize}
                \item \textbf{Direttivi}: Forniscono istruzioni chiare su come il modello dovrebbe formulare la risposta.

                \item \textbf{Specifici}: Dettagliano cosa deve essere incluso nella risposta: formato e spesso anche stile.
                
                \item \textbf{Prevedibili}: Tendono a generare risposte più prevedibili e uniformi perché il modello ha linee guida chiare da seguire.
                
                \item \textbf{Controllati}: Limitano la libertà creativa del modello, assicurando che la risposta sia strettamente correlata alla richiesta specifica dell'utente.
            \end{itemize}
            
        \subsubsection{Esempio di prompt esplicito}
            Un giornalista vuole generare un articolo breve con focus specifico sulle implicazioni economiche di un recente evento politico: \textit{``Scrivi un riassunto di 300 parole che analizza le implicazioni economiche della recente rielezione del presidente, includendo specificamente l'impatto sul mercato azionario locale e le previsioni di crescita economica per il prossimo anno''}. Questo è un esempio di prompt esplicito perché:
            \begin{itemize}
                \item \textbf{Specifica il Contenuto}: Il modello è guidato a concentrarsi sulle ``implicazioni economiche'' della rielezione del presidente.
            
                \item \textbf{Determina il Formato e la Lunghezza}: Il prompt richiede espressamente un ``riassunto di 300 parole'', fornendo una direttiva chiara sulla lunghezza e il formato della risposta.
            
                \item \textbf{Dettaglia Aspetti Specifici da Includere}: Indica specificatamente che la risposta deve trattare ``l'impatto sul mercato azionario locale'' e ``le previsioni di crescita economica per il prossimo anno'', assicurando che questi punti siano coperti nella risposta.
            \end{itemize}
            
            L'uso di prompt espliciti è particolarmente utile in contesti professionali o accademici dove sono richieste precisione e aderenza a criteri specifici. Assicurano che il modello produca risultati che sono rilevanti e utili per lo scopo specifico dell'utente, riducendo il rischio di risposte vaghe o non pertinenti.
            
            La distinzione tra prompt impliciti ed espliciti è fondamentale nel contesto del prompt engineering perché, come detto, influenza significativamente la precisione e la pertinenza delle risposte generate dai modelli di linguaggio. Questa distinzione permette di modulare il comportamento del modello in maniera più controllata e prevedibile. Riassumiamo nel seguito alcuni dei motivi per cui questa distinzione è importante (E: prompt esplicito – I: prompt implicito):
            \begin{enumerate}
                \item \textbf{Controllo sulla risposta}
                \begin{itemize}
                    \item[E.] Specificano chiaramente ciò che si desidera ottenere come risposta. Questo può includere non solo il contenuto, ma anche formato, stile o struttura della risposta.
                    \item[I.] Lasciano più spazio all'interpretazione del modello e possono essere utilizzati quando si desidera vedere come il modello elabora e risponde basandosi solo sul suo apprendimento.
                \end{itemize}

                \item \textbf{Pertinenza e precisione delle Informazioni}
                \begin{itemize}
                    \item[E.] Tendono a generare risposte più precise e direttamente correlate alle esigenze informative dell'utente. Sono particolarmente utili in contesti professionali o educativi dove la precisione e la specificità sono critiche.
                    \item[I.] Sebbene possano a volte risultare in risposte meno precise, possono stimolare risposte più creative o ampie, utili per esplorare un argomento in modi meno strutturati o per testare la capacità del modello di generare risposte innovative.
                \end{itemize}

                \item \textbf{Minimizzazione di bias e assunzioni}
                \begin{itemize}
                    \item[E.] Si riducono le possibilità che il modello si basi su assunzioni predefinite o bias non desiderati, dato che l'input fornisce direzioni chiare su cosa generare.
                    \item[I.] Lasciando più libertà interpretativa al modello, possono a volte portare a risposte che riflettono bias non riconosciuti nell'addestramento o nelle meccaniche del modello stesso.
                \end{itemize}

                \item \textbf{Efficienza nella comunicazione}
                \begin{itemize}
                    \item[E.] Promuovono una comunicazione più efficiente in situazioni dove il tempo o la chiarezza sono essenziali, come nel supporto tecnico o nelle query specifiche.
                    \item[I.] Possono essere più adatti per discussioni aperte, brainstorming o quando l'obiettivo è esplorare idee piuttosto che ottenere risposte dirette.
                \end{itemize}
            \end{enumerate}

    \subsection{Prompt espliciti vs. prompt impliciti: esempi}
        Ecco alcuni esempi pratici; con ChatGPT e Claude, che mostrano come differenti tipi di prompt (impliciti ed espliciti, impliciti) possano influenzare le risposte generate da un modello di linguaggio, fornendo anche delle spiegazioni su come e perché le risposte variano a seconda del tipo di prompt utilizzato.

        \begin{itemize}
            \item I prompt espliciti (figure \ref{fig:prompt_esplicito_chatgpt} e \ref{fig:prompt_esplicito_claude}) guidano il modello a fornire una risposta molto specifica, limitando il focus ai fattori chiave richiesti e aderendo al limite di parole impostato.
            
            \item I prompt impliciti (figure \ref{fig:prompt_impicito_chatgpt} e \ref{fig:prompt_impicito_claude}) permettono al modello più libertà interpretativa, risultando in una risposta più generica che copre il tema in modo ampio.
        \end{itemize}
        
        \begin{figure}
            \centering
            % \includegraphics[width=0.5\linewidth]{}
            \missingfigure{}
            \caption{Esempio di prompt esplicito con ChatGPT}
            \label{fig:prompt_esplicito_chatgpt}
        \end{figure}

        \begin{figure}
            \centering
            % \includegraphics[width=0.5\linewidth]{}
            \missingfigure{}
            \caption{Esempio di prompt esplicito con Claude}
            \label{fig:prompt_esplicito_claude}
        \end{figure}

        \begin{figure}
            \centering
            % \includegraphics[width=0.5\linewidth]{}
            \missingfigure{}
            \caption{Esempio di prompt implicito con ChatGPT}
            \label{fig:prompt_impicito_chatgpt}
        \end{figure}

        \begin{figure}
            \centering
            % \includegraphics[width=0.5\linewidth]{}
            \missingfigure{}
            \caption{Esempio di prompt implicito con Claude}
            \label{fig:prompt_impicito_claude}
        \end{figure}
        
    \subsection{Il fenomeno delle ``allucinazioni''}
        \todo{Da scrivere}
        
    \subsection{Strumenti di IA Generativa attraverso API}
        \todo{Da scrivere}
